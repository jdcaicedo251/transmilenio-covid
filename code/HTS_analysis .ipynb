{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTS analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a prelimiary analysis of the BRT users in the 2019 Household travel survey 2019. \n",
    "The focus of this analysis focuses on: \n",
    "- % of users living within the catchment areas\n",
    "- Mode share of the access/eggress leg in a BRT trip\n",
    "- % of transactions that are transfers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "import numpy as np \n",
    "import time \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/output/'\n",
    "input_path = '../data/input/'\n",
    "\n",
    "catchment_areas = gpd.read_file(output_path + 'tables/catchment_areas/catchment_areas.shp', crs = 'EPSG:4686')\\\n",
    "                     .rename(columns= {'station_na':'station_name'})\n",
    "\n",
    "#Bogota shapefiles \n",
    "lsoas = gpd.read_file(input_path + 'localidades_shp/Loca.shp')\n",
    "lsoas.drop(index = 8, inplace= True )\n",
    "lsoas['bog'] = 1\n",
    "bogota = lsoas.dissolve('bog')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = '../../../../02_Data/02_Encuestas de movilidad/03_2019/data_base/csv_files/'\n",
    "legs_path = 'EtapasEODH2019.csv'\n",
    "trips_path = 'ViajesEODH2019.csv'\n",
    "persons_path = 'PersonasEODH2019.csv'\n",
    "household_path = 'HogaresEODH2019.csv'\n",
    "vehicle_path = 'VehÂ°culosEODH2019.csv'\n",
    "\n",
    "households = pd.read_csv(path_to_files + household_path ,sep=',', dtype = {'Id_Hogar': np.str})#, index_col = 'Id_Hogar')\n",
    "persons = pd.read_csv(path_to_files + persons_path ,sep=',', dtype = {'id_hogar': np.str})\n",
    "trips = pd.read_csv(path_to_files + trips_path ,sep=';', dtype = {'id_hogar': np.str})\n",
    "legs = pd.read_csv(path_to_files + legs_path ,sep=';', dtype = {'id_hogar': np.str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Household sample size: 21828\n",
      "Persons sample size: 66820\n",
      "Number of trips: 134497\n",
      "Number of legs: 152310\n"
     ]
    }
   ],
   "source": [
    "print('Household sample size:', households.Id_Hogar.nunique())\n",
    "print ('Persons sample size:', persons.shape[0])\n",
    "print ('Number of trips:', trips.shape[0])\n",
    "print ('Number of legs:', legs.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assing new IDs\n",
    "Household ID is a combination of letter and numbers. Not both types in every ID. I will make a uniform type (int) to every household ID. \n",
    "\n",
    "I will also create a unique ID for a person, trip and leg. The current dataset only includes an ID within a household, but not wrt the whole sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 138 ms, sys: 60.7 ms, total: 199 ms\n",
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#Create new household numerical (with 6 digits) id. \n",
    "new_ids = range(100000, 100000 + households.Id_Hogar.nunique())\n",
    "new_id_df = pd.DataFrame({'Id_Hogar':households.Id_Hogar, \n",
    "                          'hh_id': new_ids}).set_index('Id_Hogar')\n",
    "\n",
    "households = pd.merge(households, new_id_df, how = 'left', left_on = 'Id_Hogar', right_index = True)\n",
    "persons = pd.merge(persons, new_id_df, how = 'left', left_on = 'id_hogar', right_index = True)\n",
    "trips = pd.merge(trips, new_id_df, how = 'left', left_on = 'id_hogar', right_index = True)\n",
    "legs = pd.merge(legs, new_id_df, how = 'left', left_on = 'id_hogar', right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asserting correct merging and no missing data\n",
    "tables = [households, persons, trips, legs]\n",
    "for table in tables:\n",
    "    assert table.hh_id.min() == 100000 and table.hh_id.max() == 121827\n",
    "    assert table.hh_id.isnull().sum() == 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a unique person ID - The two next digits \n",
    "persons['person_id'] = (persons.hh_id.astype(str) + persons.id_persona.astype(str).str.zfill(2)).astype(int)\n",
    "trips['person_id'] = (trips.hh_id.astype(str) + trips.id_persona.astype(str).str.zfill(2)).astype(int)\n",
    "legs['person_id'] = (legs.hh_id.astype(str) + legs.id_persona.astype(str).str.zfill(2)).astype(int)\n",
    "\n",
    "#Creating a unique trip ID - The next two digits \n",
    "trips['trip_id'] = (trips.person_id.astype(str) + trips.id_viaje.astype(str).str.zfill(2)).astype(int)\n",
    "legs['trip_id'] = (legs.person_id.astype(str) + legs.id_viaje.astype(str).str.zfill(2)).astype(int)\n",
    "\n",
    "#Creating a unique leg ID - Last digit \n",
    "legs['leg_id'] = (legs.trip_id.astype(str) + legs.id_etapa.astype(str).str.zfill(1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of users living within the catchment areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Households that have at least one trip in TM in Bogota: 6648\n",
      "Percetange of people living within the catchment areas: 89.62093862815884\n"
     ]
    }
   ],
   "source": [
    "# Households IDs that has at least one trip in TM \n",
    "BRT_modes = ['TransMilenio', 'Alimentador','Cable']\n",
    "BRT_hh_id = trips[trips.modo_principal.isin(BRT_modes)].hh_id\n",
    "\n",
    "# Filter HHs with at least one BRT mode\n",
    "cols = ['hh_id','Latitud', 'Longitud','Factor', 'municipio', 'localidad','p5_estrato']\n",
    "BRT_hhs = households[households.hh_id.isin(BRT_hh_id)][cols]\n",
    "\n",
    "# Transforming Households to a Geopandas object \n",
    "BRT_hhs = gpd.GeoDataFrame(BRT_hhs, \n",
    "                           geometry = gpd.points_from_xy(BRT_hhs.Longitud, BRT_hhs.Latitud), \n",
    "                           crs = 'EPSG:4686')\n",
    "brt_hhs = len(BRT_hhs)\n",
    "\n",
    "# Points within the Bogota area\n",
    "BRT_hhs = gpd.sjoin(trhh_gdf, bogota, op = 'within')\n",
    "brt_hhs_bogota = len(BRT_hhs)\n",
    "\n",
    "cols.append('geometry')\n",
    "print('Households that have at least one trip in TM in Bogota:', brt_hhs_bogota)\n",
    "\n",
    "#Pople within the catchment area:\n",
    "ca_people = gpd.sjoin(BRT_hhs[cols], catchment_areas, op = 'within') #catchment_areas.plot()\n",
    "print('Percetange of people living within the catchment areas:', 100*(len(ca_people))/brt_hhs_bogota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- It could be that the BRT did not initiate at home. Filter BRT trips that have origin/destination is home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRT Access/egress mode share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_mode(modes_in_list):\n",
    "    values = []\n",
    "    for ele in modes_in_list:\n",
    "\n",
    "        if len(ele)>=2:\n",
    "            value = ele.min()\n",
    "        elif len(ele)==1:\n",
    "            value = ele[0]\n",
    "        else: \n",
    "            value = 0\n",
    "        values.append(value)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shares(df, access = 'access'):\n",
    "    s = pd.Series(df.groupby(access).weight.sum()).reset_index()\n",
    "    s['Share(%)'] = (s.weight/s.weight.sum())*100\n",
    "    s = s.sort_values('Share(%)', ascending = False)\n",
    "    s = s.set_index(s[access])\n",
    "    s['Share(%)'] = s['Share(%)'].round(1)\n",
    "    return s[['Share(%)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select trips in BRT \n",
    "BRT_modes = ['TransMilenio','Cable']\n",
    "BRT_trips = trips[(trips.modo_principal.isin(BRT_modes))]\n",
    "\n",
    "BRT_legs = legs[legs.trip_id.isin(BRT_trips.trip_id)]\n",
    "\n",
    "#Cable, feeder, dual and intercity can be separeted from smartcard data.\n",
    "#Therefore, we analyses access and eggress from all these. \n",
    "BRT_legs['p18_id_medio_transporte'].replace({24:1, 3:1, 2:1, 8:1}, inplace = True)\n",
    "\n",
    "#Obtain access/egress modes for all TM trips\n",
    "BRT_legs1 = BRT_legs.groupby('trip_id').agg({'p18_id_medio_transporte': 'unique'})\n",
    "BRT_legs1 = BRT_legs1.merge(trips[['trip_id', 'f_exp']], left_index = True, right_on = 'trip_id').reset_index()\n",
    "\n",
    "#Split access and eggress\n",
    "list_ = []\n",
    "for row in BRT_legs1['p18_id_medio_transporte']:\n",
    "    index = np.where(row == 1)[0][0]\n",
    "    access = pd.Series(np.split(row, [index, index+1]))\n",
    "    list_.append(access)\n",
    "\n",
    "access_modes = pd.concat(list_, axis = 1).T\n",
    "access_modes.rename(columns = {0:'access', 1:'BRT', 2:'egress'}, inplace = True)\n",
    "\n",
    "#Transforming list to number (easier for manipulation)\n",
    "access_modes['access'] = unique_mode(access_modes.access)\n",
    "access_modes['egress'] = unique_mode(access_modes.egress)\n",
    "access_modes['BRT'] = unique_mode(access_modes.BRT)\n",
    "\n",
    "# If access or egress = 0, means access/egress = Walk\n",
    "access_modes.access.where(access_modes.access != 0, 1, inplace = True)\n",
    "access_modes.egress.where(access_modes.egress != 0, 1, inplace = True)\n",
    "access_modes\n",
    "\n",
    "# Transforming number to mode name\n",
    "dict_replace = {1: 'Walk', \n",
    "                4: 'SITP', 5: 'SITP', 6: 'SITP', 7: 'SITP', \n",
    "                19: 'Informal',  15: 'Informal', 23: 'Informal', 20: 'Informal', #Biketaxi is informal\n",
    "                16: 'Taxi', 17: 'Taxi', 18: 'Taxi', 14: 'Taxi',\n",
    "                35: 'Private vehicle', 36: 'Private vehicle', 32:'Private vehicle', 33:'Private vehicle',\n",
    "                39: 'Private vehicle',34: 'Private vehicle',\n",
    "                30: 'Bike - other nm', 31: 'Bike - other nm', 36: 'Bike - other nm', 37: 'Bike - other nm',\n",
    "                38: 'Bike - other nm', 13: 'Bike - other nm',\n",
    "                12: 'other',9:'other',10:'other',11:'other',21:'other',22:'other',25:'other', 99: 'other', \n",
    "                40: 'Walk'}\n",
    "\n",
    "access_modes.access.replace(dict_replace, inplace = True)\n",
    "access_modes.egress.replace(dict_replace, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Share(%)_access</th>\n",
       "      <th>Share(%)_egress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Walk</th>\n",
       "      <td>88.1</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITP</th>\n",
       "      <td>6.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informal</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taxi</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private vehicle</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bike - other nm</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Share(%)_access  Share(%)_egress\n",
       "Walk                        88.1             87.5\n",
       "SITP                         6.1              5.9\n",
       "Informal                     3.5              3.8\n",
       "Taxi                         0.8              1.5\n",
       "Private vehicle              0.7              0.4\n",
       "other                        0.6              0.6\n",
       "Bike - other nm              0.3              0.3"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_modes['weight'] = BRT_legs1['f_exp']\n",
    "\n",
    "access_shares = shares(access_modes, access = 'access')\n",
    "egress_shares = shares(access_modes, access = 'egress')\n",
    "access_shares.merge(egress_shares, left_index = True, \n",
    "                    right_index = True, \n",
    "                    suffixes= ['_access', '_egress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of home transactions that are transfers \n",
    "\n",
    "TO DO:\n",
    "- Get HW location \n",
    "- Get Transactions Frequent users \n",
    "- Identify HOME transactions \n",
    "- From home transactions, create dummy (1. Transfer, 0. No Transfer) \n",
    "- Get percentages of transfers and no transfers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql.functions import *\n",
    "sc = ps.SparkContext(appName=\"transfers_validations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import time \n",
    "import random \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import * #This enables the SparkSession object\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import pow, col, sqrt\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"transfers_validations\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/output/'\n",
    "input_path = '../data/input/'\n",
    "\n",
    "#HW locations\n",
    "hw_location = spark.read.csv(output_path + 'tables/hw_location.csv', header =True, sep = ',')\n",
    "\n",
    "#Transactions \n",
    "transactions = spark.read.csv(output_path + 'tables/transactions_frequent_users.csv',\n",
    "                              header =True, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[card_id: string, dt: string, fechatransaccion: string, horatransaccion: string, station_name: string, valor: string, diff_seconds: string, transactions: string, active_days: string, max_day: string, min_day: string, time_spam: string, trans_per_timespam: string, trans_per_activeday: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[card_id: string, home_station: string, transacciones_h: string, time_h: string, work_station: string, transacciones_w: string, time_w: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge hw_locations with transactions of frequent users \n",
    "df = transactions.join(hw_location, on = 'card_id', how = 'outer')\n",
    "\n",
    "# Identify home transactions \n",
    "home_origin = (df['station_name'] == df['home_station']).cast('integer')\n",
    "df = df.withColumn('home_transaction', home_origin)\n",
    "home_transactions = df.filter(col('home_transaction') == 1)#.select(col('station_name'), col('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+---------------+--------------------+-----+------------+------------+-----------+----------+----------+---------+------------------+-------------------+--------------------+---------------+-----------------+---------------+---------------+-----------------+----------------+\n",
      "| card_id|                  dt|fechatransaccion|horatransaccion|        station_name|valor|diff_seconds|transactions|active_days|   max_day|   min_day|time_spam|trans_per_timespam|trans_per_activeday|        home_station|transacciones_h|           time_h|   work_station|transacciones_w|           time_w|home_transaction|\n",
      "+--------+--------------------+----------------+---------------+--------------------+-----+------------+------------+-----------+----------+----------+---------+------------------+-------------------+--------------------+---------------+-----------------+---------------+---------------+-----------------+----------------+\n",
      "|10000172|2020-01-02T06:53:...|        20200102|       06:53:39|(04000) Cabecera ...| 1800|        null|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-03T06:13:...|        20200103|       06:13:44|(04000) Cabecera ...| 1800|       31111|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-04T06:53:...|        20200104|       06:53:55|(04000) Cabecera ...| 1800|       36600|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-09T11:34:...|        20200109|       11:34:54|(04000) Cabecera ...| 1800|       51298|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-10T12:42:...|        20200110|       12:42:01|(04000) Cabecera ...| 1800|       90427|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-11T08:19:...|        20200111|       08:19:23|(04000) Cabecera ...| 1800|       49121|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-12T11:29:...|        20200112|       11:29:54|(04000) Cabecera ...| 1800|       61567|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-13T08:17:...|        20200113|       08:17:35|(04000) Cabecera ...| 1800|       62150|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-14T08:23:...|        20200114|       08:23:08|(04000) Cabecera ...| 1800|       43854|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-16T11:56:...|        20200116|       11:56:01|(04000) Cabecera ...| 1800|       62292|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-17T08:09:...|        20200117|       08:09:18|(04000) Cabecera ...| 2400|       72797|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-20T10:35:...|        20200120|       10:35:07|(04000) Cabecera ...| 2400|      235639|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-21T07:46:...|        20200121|       07:46:33|(04000) Cabecera ...| 2400|       42872|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-22T07:49:...|        20200122|       07:49:53|(04000) Cabecera ...| 2400|       60156|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-23T09:50:...|        20200123|       09:50:24|(04000) Cabecera ...| 2400|       48506|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-24T09:38:...|        20200124|       09:38:20|(04000) Cabecera ...| 2400|       55299|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-24T17:10:...|        20200124|       17:10:19|(04000) Cabecera ...| 2400|       17168|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-25T13:37:...|        20200125|       13:37:18|(04000) Cabecera ...| 2400|       73619|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-27T20:38:...|        20200127|       20:38:02|(04000) Cabecera ...| 2400|       21737|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "|10000172|2020-01-29T08:18:...|        20200129|       08:18:53|(04000) Cabecera ...| 2400|      128451|         128|         58|2020-03-08|2020-01-02|       67|1.9104477611940298|  2.206896551724138|(04000) Cabecera ...|          135.0|8.935946502057607|(04108) El Polo|           38.0|18.43856725146199|               1|\n",
      "+--------+--------------------+----------------+---------------+--------------------+-----+------------+------------+-----------+----------+----------+---------+------------------+-------------------+--------------------+---------------+-----------------+---------------+---------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "home_transactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(valor='200'),\n",
       " Row(valor='2500'),\n",
       " Row(valor='2160'),\n",
       " Row(valor='2400'),\n",
       " Row(valor='1800')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_transactions.select('valor').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|valor|   count|\n",
      "+-----+--------+\n",
      "|  200| 5113196|\n",
      "| 2500|25376584|\n",
      "| 2160| 2474178|\n",
      "| 2400|28183114|\n",
      "| 1800| 4994646|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "home_transactions.groupby('valor').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
